{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df54e855-ea6e-42a6-8342-69871eaae3ca",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1b936-13ec-40e0-b207-c2b44ab84df0",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739aa5a0-6f7e-435d-be77-07dd4f80a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain, warnings\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb336c-f748-42a7-8984-85e15082cd03",
   "metadata": {},
   "source": [
    "#### Disable Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55cdceb8-212d-4513-8817-82e0737253fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1d959-f96a-4ef7-a6cf-ee6ec3797d79",
   "metadata": {},
   "source": [
    "#### OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f3ae73-0cca-4605-8aee-7455025bd6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = None\n",
    "with open('openai.pem', 'r') as file:\n",
    "    openai_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635c155-3897-4d5d-a338-673e2bcb9c7a",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc695fae-2424-4927-b5fa-870276b84964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIChat(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={}, openai_api_key='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', openai_api_base=None, openai_proxy=None, max_retries=6, prefix_messages=[], streaming=False, allowed_special=set(), disallowed_special='all')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=openai_key, model_name='gpt-3.5-turbo')\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91394093-1fef-42bc-b3d5-9bae6c7cc17a",
   "metadata": {},
   "source": [
    "#### Document Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea9f432-61d7-4858-aeb2-e1c0350d8152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.text_splitter.CharacterTextSplitter at 0x10be451c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = CharacterTextSplitter(\n",
    "    separator='\\n\\n',\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    # is_separator_regex=False\n",
    ")\n",
    "\n",
    "splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d0da7-fcba-4b0b-b15a-342ed78cabb9",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">\n",
    "Including 10 or more retrieved documents in a model's architecture leads to significant performance decline, regardless of the model's design. This problem arises when models need to find relevant information within lengthy contexts, causing them to overlook the provided documents. To tackle this, a suggested solution is to rearrange the retrieved documents post-retrieval, effectively preventing the drop in performance. Source: <a href=\"https://arxiv.org/abs/2307.03172\">https://arxiv.org/abs/2307.03172</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbff35-e6a9-4188-9bd3-8d6151f7a368",
   "metadata": {},
   "source": [
    "#### Load and Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4f713a-bf74-4b41-9330-18e9f7b728c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1312, which is longer than the specified 1000\n",
      "Created a chunk of size 1052, which is longer than the specified 1000\n",
      "Created a chunk of size 1235, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1207, which is longer than the specified 1000\n",
      "Created a chunk of size 1294, which is longer than the specified 1000\n",
      "Created a chunk of size 1209, which is longer than the specified 1000\n",
      "Created a chunk of size 1578, which is longer than the specified 1000\n",
      "Created a chunk of size 1838, which is longer than the specified 1000\n",
      "Created a chunk of size 1846, which is longer than the specified 1000\n",
      "Created a chunk of size 1681, which is longer than the specified 1000\n",
      "Created a chunk of size 1353, which is longer than the specified 1000\n",
      "Created a chunk of size 1354, which is longer than the specified 1000\n",
      "Created a chunk of size 1162, which is longer than the specified 1000\n",
      "Created a chunk of size 1261, which is longer than the specified 1000\n",
      "Created a chunk of size 1200, which is longer than the specified 1000\n",
      "Created a chunk of size 1152, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 1461, which is longer than the specified 1000\n",
      "Created a chunk of size 1048, which is longer than the specified 1000\n",
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1083, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('croxson.txt')\n",
    "\n",
    "document = loader.load()\n",
    "pages = splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a2eb73-536f-4f23-99bb-4c8610fd0d7e",
   "metadata": {},
   "source": [
    "#### Persist Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2cd061-df13-4269-aa6b-45ae6e2b5d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(\n",
    "    pages,\n",
    "    OpenAIEmbeddings(openai_api_key=openai_key),\n",
    "    persist_directory='./chroma_db'\n",
    ")\n",
    "\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1d805-e57b-41ee-b7dc-3950d7b6cd98",
   "metadata": {},
   "source": [
    "<a href=\"https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture\">Click here</a> to see more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
